<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>MCO: inferencia y más</title>
    <meta charset="utf-8" />
    <meta name="author" content="Paula Pereda (ppereda@correo.um.edu.uy)" />
    <link href="04_mco_II_files/remark-css/default.css" rel="stylesheet" />
    <link href="04_mco_II_files/remark-css/metropolis.css" rel="stylesheet" />
    <link href="04_mco_II_files/remark-css/metropolis-fonts.css" rel="stylesheet" />
    <link rel="stylesheet" href="my-css.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# MCO: inferencia y más
## Econometría I
### Paula Pereda (<a href="mailto:ppereda@correo.um.edu.uy" class="email">ppereda@correo.um.edu.uy</a>)
### 10 de setiembre de 2021

---

class: inverse, middle








# Regresión múltiple

---
layout: true
# Regresión múltiple

---

## Más variables explicativas


Pasamos de la **regresión lineal simple** (una .pink[variable de resultado] y una .purple[variable explicativa])

$$ \color{#e64173}{y_i} = \beta_0 + \beta_1 \color{#6A5ACD}{x_i} + u_i $$

a la tierra de la **regresión lineal múltiple** (un .pink[variable de resultado] y varios .purple[variables explicativas])

$$ \color{#e64173}{y\_i} = \beta\_0 + \beta\_1 \color{#6A5ACD}{x\_{1i}} + \beta\_2 \color{#6A5ACD}{x\_{2i}} + \cdots + \beta\_k \color{#6A5ACD}{x\_{ki}} + u\_i $$

--

**¿Por qué?**
--
 Podemos explicar mejor la variación en `\(y\)`, mejorar las predicciones, evitar el sesgo de variables omitidas, ...

---



`\(y_i = \beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + u_i \quad\)` `\(x_1\)` es continua `\(\quad x_2\)` es categórica

&lt;img src="04_mco_II_files/figure-html/mult reg plot 1-1.svg" style="display: block; margin: auto;" /&gt;

---
count: false

La intercepción y la variable categórica `\(x_2\)` controlan las medias de los grupos.

&lt;img src="04_mco_II_files/figure-html/mult reg plot 2-1.svg" style="display: block; margin: auto;" /&gt;

---
count: false

Con los medias de los grupos eliminados:

&lt;img src="04_mco_II_files/figure-html/mult reg plot 3-1.svg" style="display: block; margin: auto;" /&gt;

---
count: false

`\(\hat{\beta}_1\)` estima la relación la relación entre `\(y\)` y `\(x_1\)` después de controlar por `\(x_2\)`.

&lt;img src="04_mco_II_files/figure-html/mult reg plot 4-1.svg" style="display: block; margin: auto;" /&gt;

---
count: false

Otra manera de pensar sobre esto:

&lt;img src="04_mco_II_files/figure-html/mult reg plot 5-1.svg" style="display: block; margin: auto;" /&gt;

---
Mirar a nuestro estimador puede ayudar, también. 

Para una regresión simple `\(y_i = \beta_0 + \beta_1 x_i + u_i\)`

$$
`\begin{aligned}
  \hat{\beta}_1 &amp;= \\[0.3em]
  &amp;= \dfrac{\sum_i \left( x_i - \overline{x} \right) \left( y_i - \overline{y} \right)}{\sum_i \left( x_i -\overline{x} \right)} \\[0.3em]
  &amp;= \dfrac{\sum_i \left( x_i - \overline{x} \right) \left( y_i - \overline{y} \right)/(n-1)}{\sum_i \left( x_i -\overline{x} \right) / (n-1)} \\[0.3em]
  &amp;= \dfrac{\mathop{\hat{\text{Cov}}}(x,\,y)}{\mathop{\hat{\text{Var}}} \left( x \right)}
\end{aligned}`
$$

---
El estimador de regresión simple:

$$ \hat{\beta}_1 = \dfrac{\mathop{\hat{\text{Cov}}}(x,\,y)}{\mathop{\hat{\text{Var}}} \left( x \right)} $$

Pasando a la regresión lineal múltiple, el estimador cambia ligeramente:

$$ \hat{\beta}_1 = \dfrac{\mathop{\hat{\text{Cov}}}(\color{#e64173}{\tilde{x}_1},\,y)}{\mathop{\hat{\text{Var}}} \left( \color{#e64173}{\tilde{x}_1} \right)} $$

donde `\(\color{#e64173}{\tilde{x}_1}\)` es la variable *residualizada* `\(x_1\)`, la variación restante en `\(x\)` después de controlar las otras variables explicativas.

---
Más formalmente, considere el modelo de regresión múltiple

$$ y_i = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 + u_i $$

Nuestro `\(x_{1}\)` residualizado (que llamamos `\(\color{# e64173}{\tilde{x}_1}\)`) proviene de hacer una regresión de `\(x_1\)` en una intersección y todas las demás variables explicativas y recopilar los residuos, _es decir_,

$$
`\begin{aligned}
  \hat{x}_{1i} &amp;= \hat{\gamma}_0 + \hat{\gamma}_2 \, x_{2i} + \hat{\gamma}_3 \, x_{3i} \\
  \color{#e64173}{\tilde{x}_{1i}} &amp;= x_{1i} - \hat{x}_{1i}
\end{aligned}`
$$

--

lo que nos permite comprender mejor nuestro estimador de regresión múltiple MCO 🤓

$$ \hat{\beta}_1 = \dfrac{\mathop{\hat{\text{Cov}}}(\color{#e64173}{\tilde{x}_1},\,y)}{\mathop{\hat{\text{Var}}} \left( \color{#e64173}{\tilde{x}_1} \right)} $$
---
layout: false
class: clear, middle

&lt;img src="04_mco_II_files/figure-html/venn_iv-1.svg" style="display: block; margin: auto;" /&gt;

---
layout: true
# Regresión Múltiple

---
## Ajuste del modelo

Las medidas de *bondad de ajuste* intentan analizar qué tan bien nuestro modelo describe (*ajusta*) los datos.

**Medida común:** `\(R^2\)` [R-cuadrado] (*a.k.a.* coeficiente de determinación)

$$ R^2 = \dfrac{\sum_i (\hat{y}_i - \overline{y})^2}{\sum_i \left( y_i - \overline{y} \right)^2} = 1 - \dfrac{\sum_i \left( y_i - \hat{y}_i \right)^2}{\sum_i \left( y_i - \overline{y} \right)^2} $$

Observe a nuestro viejo amigo SCR: `\(\sum_i \left( y_i - \hat{y}_i \right)^2 = \sum_i e_i^2\)`.

--

`\(R^2\)` literalmente nos dice la parte de la varianza en `\(y\)` que representan nuestros modelos actuales. Por lo tanto `\(0 \leq R^2 \leq 1\)`.

---

**El problema:** A medida que agregamos variables a nuestro modelo, el `\(R^2\)` se incrementa *mecánicamente*.

--

Para ver este problema, podemos simular un conjunto de datos de 10.000 observaciones en `\(y\)` y 1.000 variables aleatorias `\(x_k\)`. **¡No hay relaciones entre `\(y\)` y `\(x_k\)`!**

Esquema de pseudocódigo de la simulación:
--

.pseudocode-small[

- Generamos 10.000 observaciones de `\(y\)`
- Generamos 10.000 observaciones sobre las variables `\(x_1\)` hasta `\(x_{1000}\)`
- Regresiones
  - LM&lt;sub&gt;1&lt;/sub&gt;: Regresamos `\(y\)` en `\(x_1\)`; registro R&lt;sup&gt;2&lt;/sup&gt;
  - LM&lt;sub&gt;2&lt;/sub&gt;: Regresamos `\(y\)` en `\(x_1\)` y `\(x_2\)`; registro R&lt;sup&gt;2&lt;/sup&gt;
  - LM&lt;sub&gt;3&lt;/sub&gt;: Regresamos `\(y\)` en `\(x_1\)`, `\(x_2\)`, y `\(x_3\)`; registro R&lt;sup&gt;2&lt;/sup&gt;
  - ...
  - LM&lt;sub&gt;1000&lt;/sub&gt;: Regresamos `\(y\)` en `\(x_1\)`, `\(x_2\)`, ..., `\(x_{1000}\)`; registro R&lt;sup&gt;2&lt;/sup&gt;
]

---

**El problema:** A medida que agregamos variables a nuestro modelo, el `\(R^2\)` se incrementa *mecánicamente*.

Código de .mono[R] para la simulación:



```r
set.seed(1989)
y &lt;- rnorm(1e4)
x &lt;- matrix(data = rnorm(1e7), nrow = 1e4)
x %&lt;&gt;% cbind(matrix(data = 1, nrow = 1e4, ncol = 1), x)
r_df &lt;- mclapply(X = 1:(1e3-1), mc.cores = 2, FUN = function(i) {
  tmp_reg &lt;- lm(y ~ x[,1:(i+1)]) %&gt;% summary()
  data.frame(
    k = i + 1,
    r2 = tmp_reg %$% r.squared,
    r2_adj = tmp_reg %$% adj.r.squared
  )
}) %&gt;% bind_rows()
```

---

**El problema:** A medida que agregamos variables a nuestro modelo, el `\(\color{#314f4f}{R^2}\)` se incrementa *mecánicamente*.

.center[
&lt;img src = "images/r_2.png" width = "900"&gt;]

---

**Una solución:** `\(\color{#e64173}{R^2}\)` .pink[Ajustado] 


.center[
&lt;img src = "images/r_2_adj.png" width = "900"&gt;]

---

**El problema:** A medida que agregamos variables a nuestro modelo, el `\(R^2\)` se incrementa *mecánicamente*.

**Una solución:** Penalizar por el número de variables, _por ejemplo_, `\(R^2\)` ajustado:

$$ \overline{R}^2 = 1 - \dfrac{\sum_i \left( y_i - \hat{y}_i \right)^2/(n-k-1)}{\sum_i \left( y_i - \overline{y} \right)^2/(n-1)} $$

*Nota:* El `\(R^2\)` ajustado no necesita estar entre 0 y 1.

---
layout: false
class: inverse, middle
# Incertidumbre e inferencia

---
layout: true
# Incertidumbre e inferencia
## Aprendiendo de nuestros errores

---

Como señaló nuestra simulación anterior, nuestro problema con la **incertidumbre** es que no sabemos si nuestra estimación muestral está *cerca* o *lejos* del parámetro poblacional desconocido. &lt;sup&gt;.pink[†]&lt;/sup&gt;

Sin embargo, no todo está perdido. Podemos usar los errores `\(\left (e_i = y_i - \hat {y}_i\right)\)` para tener una idea de qué tan bien nuestro modelo explica la variación observada en `\(y\)`.

Cuando nuestro modelo parece estar haciendo un "buen" trabajo, es posible que tengamos un poco más de confianza al usarlo para conocer la relación entre `\(y\)` y `\(x\)`.

Ahora solo tenemos que formalizar lo que realmente significa un "buen trabajo".

.footnote[.pink[†]: Excepto cuando corremos la simulación nosotros mismos, por eso nos gustan las simulaciones.]

---

En primer lugar, estimaremos la varianza de `\(u_i\)` (recordemos: `\(\mathop{\text{Var}}\left(u_i \right) = \sigma^2\)`) usando nuestros errores al cuadrado, _es decir_,

$$ s^2 = \dfrac{\sum_i e_i^2}{n - k} $$

donde `\(k\)` nos da el número de términos de constantes y variables que estimamos, _ejemplo_, `\(\ beta_0\)` y `\(\beta_1\)` darían `\(k = 2\)`.

`\(s^2\)` es un estimador insesgado de `\(\sigma^2\)`.

---

Luego mostramos que la varianza de `\(\hat{\beta}_1\)` (para una regresión lineal simple) es

$$ \mathop{\text{Var}} \left( \hat{\beta}_1 \right) = \dfrac{s^2}{\sum_i \left( x_i - \overline{x} \right)^2} $$

lo que muestra que la varianza de nuestro estimador de pendiente:

1. aumenta a medida que nuestras residuos se vuelven más ruidosas
2. disminuye a medida que aumenta la varianza de `\(x\)`


---


*Más comúnmente:* El **error estándar** de `\(\hat{\beta}_1\)`

$$ \mathop{\hat{\text{EE}}} \left( \hat{\beta}_1 \right) = \sqrt{\dfrac{s^2}{\sum_i \left( x_i - \overline{x} \right)^2}} $$

*Recuerden:* El error estándar de un estimador es la desviación estándar de la distribución del estimador.

---

El error estándar en .mono[R]'s `lm`, se ve así:


```r
tidy(lm(y ~ x, pop_df))
```

```
&gt; # A tibble: 2 x 5
&gt;   term        estimate std.error statistic  p.value
&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
&gt; 1 (Intercept)    2.53     0.422       6.00 3.38e- 8
&gt; 2 x              0.567    0.0793      7.15 1.59e-10
```


---

Usamos el error estándar de `\(\hat{\beta}_1\)`, junto con el propio `\(\hat{\beta}_1\)`, para aprender sobre el parámetro `\(\beta_1\)`.

Después de derivar la distribución de `\(\hat{\beta}_1\)`, &lt;sup&gt;.pink[†]&lt;/sup&gt; tenemos dos opciones (relacionadas) para la inferencia estadística formal (aprendizaje) sobre nuestro parámetro desconocido `\(\beta_1\)`:

- **Intervalos de confianza:** Utilizar la estimación y su error estándar para crear un intervalo que, cuando se repite, generalmente &lt;sup&gt;.pink[††]&lt;/sup&gt; contendrá el parámetro verdadero.

- **Pruebas de hipótesis:** Determinan si existe evidencia estadísticamente significativa para rechazar un valor o rango de valores hipotéticos.

.footnote[
.pink[†]: *Pista:* es normal con la media y la varianza que hemos derivado/discutido anteriormente)
&lt;br&gt;
.pink[††]: _Ejemplo_, los intervalos de confianza del 95% construidos de manera similar contendrán el parámetro verdadero el 95% del tiempo.
]


---
layout: true
# Incertidumbre e inferencia
## Intervalos de confianza

Construimos intervalos de confianza nivel `\((1-\alpha)\)` para `\(\beta_1\)`
$$ \hat{\beta}\_1 \pm t\_{\alpha/2,\text{gl}} \, \mathop{\hat{\text{EE}}} \left(\hat{\beta}\_1\right) $$

---

`\(t_{\alpha/2,\text{gl}}\)` denota el `\(\alpha/2\)` cuantial de una distribución `\(t\)` con `\(n-k\)` grados de libertad.

---

Por ejemplo, 100 obs., dos coeficientes (_es decir_, `\(\hat{\beta}_0\)` y `\(\hat{\beta}_1 \ \text{implica} \ k = 2\)`) y `\(\alpha = 0.05\)` (para un intervalo de confianza del 95%) nos da `\(t_ {0.025, \, 98} = -1.98\)`


&lt;img src="04_mco_II_files/figure-html/t dist-1.svg" style="display: block; margin: auto;" /&gt;

---

**Ejemplo:**

```r
lm(y ~ x, data = pop_df) %&gt;% tidy()
```

```
&gt; # A tibble: 2 x 5
&gt;   term        estimate std.error statistic  p.value
&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
&gt; 1 (Intercept)    2.53     0.422       6.00 3.38e- 8
*&gt; 2 x              0.567    0.0793      7.15 1.59e-10
```

--


Nuestro intervalo de confianza del 95% es `\(0.567\pm1.98\times0.0793= \left[0.410, \, 0.724 \right]\)`

---
layout: true
# Incertidumbre e inferencia
## Intervalos de confianza

---

Así que tenemos un intervalo de confianza para `\(\beta_1\)`, _i.e._, `\(\left[ 0.410,\, 0.724 \right]\)`.

Y... ¿qué significa?

--

**Informalmente:** El intervalo de confianza nos da una región (intervalo) en la que podemos depositar algo de confianza (confianza) para contener el parámetro.

-

**Más formalmente:** Si muestrea repetidamente de nuestra población y construye intervalos de confianza para cada una de estas muestras, `\((1- \alpha)\)` por ciento de nuestros intervalos (_ejemplo_, 95%) contendrá el parámetro de población *en algún lugar del intervalo*.

--

De nuevo a nuestra simulación...

---
Extrajimos 10.000 muestras (cada una de tamaño `\(n = 30\)`) de nuestra población y estimamos nuestro modelo de regresión para cada una de estas simulaciones:

$$ y_i = \hat {\beta}_0 + \hat{\beta}_1 x_i + e_i $$
&lt;center&gt; (repetido 10.000 veces) &lt;/center&gt;

Ahora, estimemos intervalos de confianza del 95% para cada uno de estos intervalos...
---



**De nuestras simulaciones previas:** 97.6% el 95% de los intervalos de confianza contienen el verdadero valor de parámetro de `\(\beta_1\)`.

&lt;img src="04_mco_II_files/figure-html/simulation ci-1.svg" style="display: block; margin: auto;" /&gt;

---
layout: true
# Incertidumbre e inferencia
## Testeo de hipotesis

---

En muchas aplicaciones, queremos saber más que una estimación puntual o un rango de valores. Queremos saber qué dice nuestra evidencia estadística sobre las teorías existentes.

Queremos probar hipótesis planteadas por funcionarios, políticos, economistas, científicos, amigos, vecinos raros, *etcétera*.

.hi-slate[Ejemplos]

- ¿El aumento de la presencia policial **reduce la delincuencia**?
- ¿Construir un muro gigante **reduce el crimen**?
- ¿El cierre de un gobierno **afecta negativamente a la economía**?
- ¿El cannabis legal **reduce la conducción en estado de ebriedad** o **reduce el uso de opiáceos**?
- ¿Los estándares de calidad del aire **aumentan la salud** y/o **reducen el empleo**?

---

La prueba de hipótesis se basa en resultados e intuición muy similares.

Si bien la incertidumbre ciertamente existe, aún podemos construir pruebas estadísticas *confiables* (rechazando o no rechazando una hipótesis planteada).

--

.hi-slate[MCO prueba *t*] Nuestra hipótesis (nula) establece que `\(\beta_1\)` es igual a un valor `\(c\)`, _por ejemplo_, `\(\left.H_{0} \ \right) \beta_{1}=0\)`

Bajo los supuestos del modelo lineal clásico (MLC),

$$ t_\text{estadístico} = \dfrac{\hat{\beta}_1 - c}{\mathop{\hat{\text{EE}}} \left( \hat{\beta}_1 \right)} $$

sigue una distribución `\(t\)` con `\(n-k\)` grados de libertad.

---

Para una prueba **de dos caras** de nivel $\alpha $, rechazamos la hipótesis nula (y concluimos con la hipótesis alternativa) cuando

$$ \left|t\_\text{estadístico}\right| &gt; \left|t\_{1-\alpha/2,\,df}\right| $$
lo que significa que nuestra **estadística de prueba es más extrema que el valor crítico**.

Alternativamente, podemos calcular el **valor p** que acompaña a nuestra estadística de prueba, que efectivamente nos da la probabilidad de ver nuestra estadística de prueba *o una estadística de prueba más extrema* si la hipótesis nula fuera cierta.

Valores p muy pequeños (generalmente &lt; 0.05) significan que sería improbable ver nuestros resultados si la hipotesis nula fuera realmente cierta; tendemos a rechazar el valor nulo para valores p por debajo de 0.05.

---

.mono[R] y .mono[Stata] testean por defecto contra el valor cero.


```r
lm(y ~ x, data = pop_df) %&gt;% tidy()
```

```
&gt; # A tibble: 2 x 5
&gt;   term        estimate std.error statistic  p.value
&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
&gt; 1 (Intercept)    2.53     0.422       6.00 3.38e- 8
*&gt; 2 x              0.567    0.0793      7.15 1.59e-10
```
--

`\(\left.H_{0} \ \right)\ \beta_1 = 0\)` *vs.* `\(\left.H_{1} \ \right)\ \beta_1 \neq 0\)`

¿Qué observamos del valor-p?

El valor-*p* `\(&lt; 0.05\)`. 

--

 `\(t_\text{stat} = 7.15\)` y `\(t_\text{0.975, 28} = 2.05\)`
--
 lo que implica que el valor-*p* `\(&lt; 0.05\)`. 

--

Entonces, .hi[rechazamos H.sub[0]].

---

¡De vuelta a nuestra simulación! Veamos qué está haciendo realmente nuestra estadística de `\(t\)`.

En esta situación, podemos conocer (y hacer cumplir) la hipótesis nula, ya que generamos los datos.

Para cada una de las 10.000 muestras, calcularemos la estadística `\(t\)`, y luego podremos ver cuántas estadísticas de `\(t\)` exceden nuestro valor crítico (2.05, como encima).

La respuesta debería ser aproximadamente el 5 por ciento, nuestro nivel `\(\alpha\)`.

---
layout: true
# Incertidumbre e inferencia

---



En nuestra simulación, el porcentaje 2.4 de nuestras estadísticas de `\(t\)` rechaza la hipótesis nula.

La distribución de nuestras estadísticas de `\(t\)` (sombreando las regiones de rechazo).

&lt;img src="04_mco_II_files/figure-html/simulation t plot-1.svg" style="display: block; margin: auto;" /&gt;

---



En consecuencia, 2.4 % de nuestros p-valores rechazan la hipótesis nula.

La distribución de nuestros valores p (sombreando los valores p por debajo de 0,05).
&lt;img src="04_mco_II_files/figure-html/simulation p plot-1.svg" style="display: block; margin: auto;" /&gt;

---
layout: false
class: inverse, middle
# Aplicaciones en .mono[R]

---
#Ejercicio C3.1 (Wooldridge)

.center[
&lt;img src="images/c3_1.png" width="800"&gt;]
---
#Ejercicio C3.2 (Wooldridge)

.center[
&lt;img src="images/c3_2.png" width="800"&gt;]
---
#Ejercicio C3.4 (Wooldridge)

.center[
&lt;img src="images/c3_4.png" width="800"&gt;]

---
Se dispone de una muestra de 30 observaciones de datos que 	representan salario y experiencia laboral de economistas de Montevideo en 2013 y 2014. Las variables son: `\(y\)` = salario (en miles USD); `\(x\)` = experiencia posterior a recibirse (años).

Se tiene el siguiente modelo:

`$$\mathrm{y}_{\mathrm{i}}=\beta_{1}+\beta_{2} \mathrm{x}_{\mathrm{i}}+\varepsilon_{\mathrm{i}}$$`
Se sabe que:

`$$\sum_{i=1}^{30} y_{i}^{2}=65692,27 \ ; \sum_{i=1}^{30} y_{i}=1365,1 \ ; \sum_{i=1}^{30} y_{i} x_{i}=26046,9$$`
`$$\sum_{i=1}^{30} x_{i}^{2}=12230 \ ; \ \sum_{i=1}^{30} x_{i}=550$$`
`$$\mathrm{SCR}=3089,95 \ ; \mathrm{SCT}=3574,67$$`

---
1.1	Estime por mínimos cuadrados ordinarios los parámetros de dicho modelo.

1.2	Calcule la matriz de varianzas y covarianzas de los coeficientes estimados.

1.3	Interprete los resultados obtenidos y analice su significancia estadística.

1.4	Calcular el R2 del modelo. ¿Qué puede decir al respecto?

1.5	¿Qué relación debería encontrarse entre el vector de residuos y las variables explicativas?


---

.center[
&lt;img src="images/ej.png" width="800"&gt;]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
