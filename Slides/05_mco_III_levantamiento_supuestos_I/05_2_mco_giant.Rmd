---
title: "Gran MCO"
subtitle: "Econometría I"
author: "Paula Pereda (ppereda@correo.um.edu.uy)"
date: "17 de setiembre de 2021"
output:
  xaringan::moon_reader:
    css: ['default', 'metropolis', 'metropolis-fonts', 'my-css.css']
    # self_contained: true
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---
class: inverse, middle

```{r Setup, include = F}
options(htmltools.dir.version = FALSE)

pacman::p_load(ggplot2, ggthemes, AER, dplyr, knitr)
# Define pink color
red_pink <- "#e64173"
# Knitr options
opts_chunk$set(
  comment = ">",
  fig.align = "center",
  fig.height = 7,
  fig.width = 10.5,
  # dpi = 300,
  # cache = T,
  warning = F,
  message = F
)
```
# .mono[R] + MCO con un regresor
---
# 1. Tamaño de las clases & notas

Un investigador desea analizar la relación entre el tamaño de la clase (medido por la proporción de alumnos por profesor) y el puntaje promedio de la prueba. Por lo tanto, mide ambas variables en 10 clases diferentes y termina con los siguientes resultados.

- .pink[Tamaño de la clase:] 23 19 30 22 23 29 35 36 33 25
- .pink[Puntaje de prueba:] 430	430	333	410	390	377	325	310	328	375

.ul[Instrucciones]

Cree los vectores cs (el tamaño de la clase) y ts (la puntuación de la prueba), que contengan las observaciones anteriores.


```{r, hide = TRUE}
cs <- c(23, 19, 30, 22, 23, 29, 35, 36, 33, 25)
ts <- c(430, 430, 333, 410, 390, 377, 325, 310, 328, 375)
```

---
# 2. Estadísticos descriptivos

## Media, varianza, covarianza y correlación

Los vectores cs y ts están disponibles en el ambiente (pueden comprobar esto: escriba el nombre de los objetos en la consola y presione enter).
 
.ul[Instrucciones]

- Calcular la media, la varianza muestral y la desviación estándar muestral de ts.

- Calcular la covarianza y el coeficiente de correlación para ts y cs.

.hi-pink[Sugerencia:] Utilice las funciones de R: mean(), sd(), cov(), cor() y var().

---
# 2. Estadísticos descriptivos

## Media, varianza, covarianza y correlación

```{r, hide = TRUE}
# computa la media, varianza y desviación estándar de las notas
mean(ts)
sd(ts)
var(ts)

# computa la covarianza y el coeficiente de correlación
cov(ts, cs)
cor(ts, cs)
```

---
# 3. Regresión lineal simple 

Los vectores cs y ts están disponibles en el entorno de trabajo.

.ul[Instrucciones]:

- Utilice lm() para estimar el modelo de regresión:

$$\text{TestScore}_{i}=\beta_{0}+\beta_{1} \text{ClassSize}_{i}+u_{i}$$

- Asigne el resultado a mod.

- Obtenga un resumen estadístico del modelo.

---
# 3. Regresión lineal simple 

```{r, hide = TRUE}
# estime el modelo 
# lm(ts ~ cs)

# le asigna el nombre mod

mod <- lm(ts ~ cs)

# obtiene un resumen del modelo
summary(mod)
```
---
# El modelo como objeto

Veamos cómo se estructura un objeto de clase lm.
 
Los vectores cs y ts, así como el modelo de objeto del ejercicio anterior, están disponibles en el ambiente.
 
.ul[Instrucciones]:
   
- Use class() para chequear la clase del objeto mod.

- mod es un objeto de tipo lista con entradas con nombre. Verifique esto usando la función is.list().

- Vea qué información puede obtener de mod usando names().

- Leer una entrada arbitraria del objeto mod usando el operador $.

---
# El modelo como objeto

```{r, hide = TRUE}
# chequee de qué clase es `mod`
class(mod)

# use `is.list()` en `mod`
is.list(mod)

# chequee qué contiene `mod` usando `names()`
names(mod)

# use el operador `$` en `mod`
## ejemplo:
mod$fitted.values
```
---
# Graficando la regresión

Sabiendo que plot() se utiliza para graficar y permite ver la dispersión.

.ul[Instrucciones]:
  
- Agregue la línea de regresión al diagrama de dispersión.

- El objeto mod está disponible en el ambiente.

.hi-pink[Sugerencia:] Use la función abline().

---
# Graficando la regresión

```{r, hide = TRUE}
# agregue la línea de regresión al gráfico de puntos
plot(cs, ts)

abline(mod)
```

---
# Resumen del modelo

Ahora lea y almacene parte de la información contenida en la salida de summary().

.ul[Instrucciones]:
  
- Asigne la salida de resumen (mod) al objeto s.

- Compruebe los nombres de entrada de los objetos.

- Cree un nuevo objeto R2 y asigne el R2 de la regresión.

- El objeto mod está disponible en el ambiente.

---
# Resumen del modelo

```{r}
# asigna el resumen del modelo al objeto `s`
s <- summary(mod)

# chequea el nombre de las entradas en `s`
names(s)

# almacena el R^2 de ka regresión en el objeto `R2`
R2 <- s$r.squared
```

---
# Coeficientes estimados 

La función de resumen summary() también proporciona información sobre la significancia estadística de los coeficientes estimados.

.ul[Instrucciones]:
  
- Extraiga la matriz de 2×4 con coeficientes estimados, errores estándar, estadísticos t y valores p correspondientes al resumen del modelo s

- Guarde esta matriz en un objeto llamado coefs

- Los objetos mod y s están disponibles en su ambiente.

```{r}
# almacene los coeficientes de la matriz a `coefs`
coefs <- s$coefficients
```

---
# 8. Dejando el intercepto

Hasta ahora, hemos estimado modelos de regresión que consisten en un intercepto y un regresor único. En este ejercicio aprenderemos a especificar y estimar...

Tenga en cuenta que excluir el intercepto de un modelo de regresión puede ser una práctica poco fiable en algunas aplicaciones, ya que impone la función de expectativa condicional de t

.ul[Instrucciones]:
  
- Averigüe cómo se debe especificar el argumento de la fórmula para una regresión de ts únicamente en cs, es decir, una regresión sin intersección. ¡Google es tu amigo!
  
- Estime el modelo de regresión sin intersección y almacene el resultado en mod_ni.

- Los vectores cs, ts y el modelo de objeto mod de ejercicios anteriores están disponibles en el ambiente.

---
# 8. Dejando el intercepto

```{r}
# regrese `ts` solamente en `cs`. Almacene el resultado en `mod_ni`.
mod_ni <- lm(ts ~ cs - 1) 

# o 
lm(ts ~ cs + 0)
```

---
# 9. El caso sin intercepto

En el ejercicio 8 ha estimado un modelo sin intersección. La función de regresión estimada es

$$\widehat{\text{TestScore}}=12.65 \times \text{ClassSize}$$

con un error estándar de 1.36.


.ul[Instrucciones]:
  
- Convénzase de que todo es como se indicó anteriormente: extraiga la matriz de coeficientes del resumen de mod_ni y guárdelo en una variable llamada coef.

- Los vectores cs, ts y el objeto modelo mod_ni del ejercicio anterior están disponibles en su entorno de trabajo.

---
# 9. El caso sin intercepto

.hi-pink[Sugerencia:] Se puede acceder a una entrada de una lista con nombre usando el operador $.

```{r}
# extraiga la matriz de coeficientes del resumen del modelo y almacénelo como `coef`
coef <- summary(mod_ni)$coefficients

## ¡Correcto! Tenga en cuenta que solo hay una estimación de coeficiente (el coeficiente de cs) 
## informado por resumen(mod_ni).
```
---
# 10. El caso sin intercepto

En los ejercicios 8 y 9 se ha tratado con un modelo sin intercepto. La función de regresión estimada fue

$$\widehat{\text{TestScore}}=12.65 \times \text{ClassSize}$$

con un error estándar de 1.36.

El coeficiente de la matriz de coeficientes del ejercicio 9 contiene el coeficiente estimado en ClassSize, su error estándar, el estadístico t de la prueba de significancia y el valor p correspondiente.

.ul[Instrucciones]:
  
- Imprima el contenido de coef en la consola.

- Convénzase usted mismo de que el estadístico t informado es correcto: use las entradas de coef para calcular el estadístico t y guárdelo en t_stat.

- El coeficiente de matriz del ejercicio anterior está disponible en su ambiente.

---


# 10. El caso sin intercepto

.hi-pink[Sugerencias] 

- Recuerden que $X[a, b]$ devuelve el elemento $[a, b]$ de la matriz  $X$.

- El estadístico t para una prueba del tipo $H_{0}: \beta_{1}=0$ se computa de la siguiente manera:

$$t=\frac{\hat{\beta}_{1}}{ee\left(\hat{\beta}_{1}\right)}$$


```{r}
# imprima los contenidos de `coef` en la consola
print(coef)

# compute el estadístico t manualmente y asígnelo a `t_stat`
t_stat <- coef[1,1]/coef[1,2]
```

---
# 11. Dos regresiones, un gráfico

Los dos modelos de regresión estimados de los ejercicios anteriores son

$$\text {TestScore}_{i}=12.65 \times \text {ClassSize}_{i}$$
y 

$$\text {TestScore}_{i}=567.4272-7.1501 \times \text {ClassSize}_{i}$$

Se le proporciona el código plot(cs, ts) que crea un diagrama de dispersión de ts y cs. Tenga en cuenta que esta línea debe ejecutarse antes que abline(), además, pueden colorear las líneas de regresión usando, por ejemplo, col = "red" o col = "blue" como un argumento adicional a abline() para una mejor distinción. Los vectores cs y ts, así como la lista de objetos mod y mod_ni de ejercicios anteriores, están disponibles en su ambiente.

.ul[Instrucciones]:
  
- Genere un diagrama de dispersión de ts y cs y agregue las líneas de regresión estimadas de mod y mod_ni.

---
# 11. Dos regresiones, un gráfico

```{r}
# se grafica la línea de regresiòn de ambos modelos
plot(cs, ts)
abline(mod, col = "blue")
abline(mod_ni, col = "red")
```

---
# 12. SRy ST

Si la inspección gráfica no ayuda, los investigadores recurren a técnicas analíticas para detectar si un modelo se ajusta bien o mejor a los datos que otro modelo.

Volvamos al modelo de regresión simple que incluye un intercepto. La línea de regresión estimada para mod fue

$$\text { TestScore }_{i}=567.43-7.15 \times \text { ClassSize }_{i}, R^{2}=0.8976, ESR=15.19$$

Puede comprobar esto como mod y los vectores cs y ts están disponibles en su ambiente.

.ul[Instrucciones]:

- Calcular la SR, la suma de los residuos al cuadrado y guárdelo en ssr.

- Calcular la ST, la suma total de cuadrados y guárdelo en tss.

.hi-pink[Nota]: `var ()` calcula la varianza de la muestra insesgada. => corrija esto multiplicando con (n-1) = 9
---
# 12. SR y ST

```{r}
# compute la SR y almacénela en `ssr`
ssr <- sum(mod$residuals^2)

# compute la ST y almacénela en `tss`
tss <- 9*var(ts)
```
---
# 13. El $R^2$

El $R^2$ de la regresión guardada en mod es 0.8976. Puede verificar esto ejecutando summary(mod)$r.squared en la consola a continuación.

Recuerda que la fórmula de $R^2$ es: 

$$R^{2}=\frac{SE}{ST}=1-\frac{SR}{ST}$$
.ul[Instrucciones]:

- Utilice ssr (SR) y tss (ST) para calcular $R^2$ a mano. Redondea el resultado a cuatro decimales y guárdelo en R2.

- Use el operador lógico == para verificar si su resultado coincide con el valor mencionado anteriormente.

---
# 13. El $R^2$

```{r}
# computa R^2, redonde a cuatro lugares después de la coma y guárdelo como "R2"
R2 <- round(1-ssr/tss,4)

# chequea si el resultado es correcto usando el operador "=="
R2 == 0.8976
```

---
# 14. El error estándar de una regresión

El error estándar de un modelo de regresión simple es 

$$ESR=\frac{1}{n-2} \sum_{i=1}^{n} \widehat{u}_{i}^{2}=\sqrt{\frac{SR}{n-2}}$$
El ESR mide el tamaño de un residuo promedio que es una estimación de la magnitud de un error de regresión típico.

El modelo de objeto mod y los vectores cs y ts están disponibles en su ambiente.

.ul[Instrucciones]:

- Utilice summary() para obtener el ESR para la regresión de ts sobre cs guardado en el objeto modelo mod. Guarde el resultado en la variable SER.

- Utilice SER para calcular el SR y guárdelo en SSR.

- Compruebe que SSR es de hecho el SR comparando SSR con el resultado de sum(mod$residuals^2).

---
# 14. El error estándar de una regresión

```{r}
# obtenga el SER usando `summary()` y guárdelo `SER`
SER <- summary(mod)$sigma

# compute el SSR y almacénelo como `SSR`
SSR <- SER^2*(length(ts)-2)

# haga la comapración
SSR == sum(mod$residuals^2)
```

---
# 15. La matriz de covarianza

Como se discute en el capítulo 4 del Stock & Watson, los estimadores MCO $\widehat{\boldsymbol{\beta}}_{\mathbf{0}}$ y $\widehat{\boldsymbol{\beta}}_{\mathbf{1}}$ son funciones del término de error aleatorio. Por tanto, son variables aleatorias en sí mismas. Para dos o más variables aleatorias, sus covarianzas y varianzas se resumen mediante una matriz de varianza-covarianza (que a menudo se denomina simplemente matriz de covarianza). Tomando la raíz cuadrada de los elementos diagonales de la matriz de covarianza estimada se obtiene $ee\left(\widehat{\beta}_{0}\right)$ y $ee\left(\widehat{\beta}_{1}\right)$, los errores estándar de $\widehat{\boldsymbol{\beta}}_{\mathbf{0}}$ y $\widehat{\boldsymbol{\beta}}_{\mathbf{1}}$.

summary() computa una estimación de esta matriz. La entrada respectiva en el output of summary (recuerden que summary() produce una lista) se llama cov.unscaled. El objeto del modelo mod is disponible en su ambiente. 
Instructions:

.ul[Instrucciones]:

- Utilice summary() para obtener la estimación de la matriz de covarianzas para la regresión de los puntajes de las pruebas en las proporciones alumno-maestro almacenadas en el modelo de objeto mod. Guarde el resultado en cov_matrix.

- Obtenga los elementos diagonales de cov_matrix, calcule su raíz cuadrada y asigne el resultado al objeto SEs (errores estándar).

.hi-pink[Sugerencia:] diag(A) devuelve un vector que contiene los elementos diagonales de la matriz A.

---
# 15. La matriz de covarianza

```{r}
# obtenga la matriz y almacénela como `cov_matrix`
cov_matrix <- summary(mod)$cov.unscaled

# compute los errores estándar y asignelos en el vector `SEs`
SEs <- sqrt(diag(cov_matrix))
```
---
# 16. Testeando hipótesis nulas

Considere el modelo de regresión estimado:

$$\text { TestScore }_{i}=567.43-7.15 \times \text { ClassSize }_{i}, R^{2}=0.8976, ESR=15.19$$
con $ee\left(\widehat{\beta}_{0}\right) = 23.96$ y $ee\left(\widehat{\beta}_{1}\right) = 0.85$

.ul[Instrucciones]:

- Compute el valor-p para una prueba t de la hipótesis de que el intercepto es cero frente a la alternativa de dos lados que no es cero. Guarde el resultado en p_int.

- Compute el valor-p para una prueba t de la hipótesis de que ClassSize es cero frente a la alternativa de dos lados que no es cero. Guarde el resultado en p_STR.

.hi-pink[Sugerencia:] Ambas hipótesis se pueden probar individualmente mediante una prueba de dos lados. Utilice pnorm() para obtener probabilidades acumuladas de resultados estándar distribuidos normalmente.
---
# 16. Testeando hipótesis nulas

```{r}
# compute el valor-p para el primer test de significancia y guárdelo en p_int
t_int <- 567.43/23.9606
p_int <- 2*(1-pnorm(abs(t_int)))

# compute el valor-p para el segundo test de significancia y guárdelo en p_cs
t_STR <- 7.15/0.8536
p_STR <- 2*(1-pnorm(abs(t_STR)))
```
---
# 17. Testeando hipótesis nulas

Considere de nuevo el modelo de regresión estimado:

$$\text { TestScore }_{i}=567.43-7.15 \times \text { ClassSize }_{i}, R^{2}=0.8976, ESR=15.19$$
con $ee\left(\widehat{\beta}_{0}\right) = 23.96$ y $ee\left(\widehat{\beta}_{1}\right) = 0.85$

¿Se puede rechazar la hipótesis nula discutida en el ejercicio anterior usando pruebas t individuales al 5%? Los objetos t_int y t_STR son los estadísticos t. Ambos están disponibles en el ambiente. 

.ul[Instrucciones]: Junte t_int y t_STR en un vector y use operadores lógicos para verificar si se aplica la regla de rechazo correspondiente.

.hi-pink[Sugerencia:] Ambas pruebas son pruebas t bilaterales. El concepto clave 5.2 resume cómo se realiza una prueba t bilateral. Utilice qnorm() para obtener valores críticos normales estándar.

---
# 17. Testeando hipótesis nulas

```{r}
test <- c(t_int, t_STR)
# el resultado es `TRUE` si se rechaza la hipótesis nula
abs(test) >= qnorm(0.975)
```

---
# 18. Intervalo de confianza

mod, el objeto de clase lm contiene los resultados de la siguiente regresión 

$$\text { TestScore }_{i}=567.43-7.15 \times \text { ClassSize }_{i}, R^{2}=0.8976, ESR=15.19$$
con $ee\left(\widehat{\beta}_{0}\right) = 23.96$ y $ee\left(\widehat{\beta}_{1}\right) = 0.85$

está en su ambiente de trabajo 

.ul[Instrucciones]: Compute intervalos de confianza al 90% para ambos coeficientes. 

.hi-pink[Sugerencia:] Use la función confint(), vea ?confint. El argumento level establece el nivel de confianza que se utilizará.

```{r}
confint(mod, level = 0.9)
```

---
class: inverse, middle

# .mono[R] + MCO con múltiples regresores
---

# 1. Regresión lineal múltiple

En el transcurso de esta sección, trabajará con Boston, el conjunto de datos de Boston Housing que contiene 506 observaciones sobre el valor de las viviendas en los suburbios de Boston. Boston viene con el paquete MASS.

.ul[Instrucciones]: 

- Cargue tanto el paquete como el conjunto de datos.

- Obtenga una descripción general de los datos utilizando funciones conocidas de los prácticos anteriores.

- Estime un modelo de regresión lineal simple que explique el valor medio de la vivienda de los distritos (medv) por los porcentajes de hogares con un nivel socioeconómico bajo, lstat y una constante. Guarde el modelo en bh_mod.

- Imprima un resumen de coeficientes en la consola que informa de errores estándar robustos.

.hi-pink[Sugerencia:]  Solo necesitarán funciones básicas de R: library(), data(), lm() y coeftest().

---
# 1. Regresión lineal múltiple

```{r}
# cargue el paquete y los datos
library(MASS)
data("Boston")
# chequeen los datos 
summary(Boston)

```

---
# 1. Regresión lineal múltiple

```{r}
# o
str(Boston)
# o
head(Boston)

```
---
# 1. Regresión lineal múltiple

```{r}

# estime un modelo de regresión simple
bh_mod <- lm(medv ~ lstat, data = Boston)
# imprima en la consola el resumen 
coeftest(bh_mod, vcov. = vcovHC)
R2_res <- summary(bh_mod)$r.squared
```
---
# 2. Regresión lineal múltiple

Ahora, ampliemos el enfoque del ejercicio anterior agregando regresores adicionales al modelo y estimándolo nuevamente.

Como se discute en el capítulo 6, agregar regresores al modelo mejora el ajuste de modo que el ESR disminuye y el $R^2$ aumenta. El objeto modelo bh_mod está disponible en el ambiente.

.ul[Instrucciones]: 

- Regresar el valor medio de la vivienda en un distrito, medv, sobre la edad promedio de los edificios, la edad, la tasa de delincuencia per cápita, crim, el porcentaje de personas con un nivel socioeconómico bajo, lstat y una constante. Dicho de otra manera, estima el modelo

$$\operatorname{med} v_{i}=\beta_{0}+\beta_{1} \text {lstat}_{i}+\beta_{2} \text { age }_{i}+\beta_{3} \text { crim}_{i}+u_{i}$$
- Imprima un resumen de coeficientes en la consola que informa errores estándar robustos para el nuevo modelo.

- El $R^2$ del modelo de regresión simple se almacena en R2_res. Guarde el $R^2$ del modelo de regresión múltiple en R2_unres y compruebe si el modelo de regresión múltiple produce un mayor $R^2$. 

---
# 2. Regresión lineal múltiple

```{r}
# estime la regresión
mod <- lm(medv ~ lstat + crim + age, data = Boston)

# obtenga un resumen de los coeficientes estimados
coeftest(mod, vcov. = vcovHC)

# compare los R2
R2_unres <- summary(mod)$r.squared
R2_unres < R2_res
```

---
# 3. Test de hipótesis 

Reconsidere el modelo estimado en el ejercicio anterior 

$$\widehat{m e d v}_{i}=32.828-0.994 \times l s t a t_{i}-0.083 \times c r i m_{i}+0.038 \times a g e_{i}$$

con $ee\left(\widehat{\beta}_{0}\right) = 0.75$, $ee\left(\widehat{\beta}_{1}\right) = 0.05$, $ee\left(\widehat{\beta}_{3}\right) = 0.04$ y $ee\left(\widehat{\beta}_{4}\right) = 0.01$  

Al igual que en el marco de regresión lineal simple, podemos realizar pruebas de hipótesis sobre los coeficientes en modelos de regresión múltiple. La hipótesis más común es ${H}_{0}: \beta_{j}=0$ contra la alternativa ${H}_{1}: \beta_{j} \neq 0$ para algunos
$j$ en $0,1, \ldots, k$.

Las estimaciones de los coeficientes, así como los errores estándar correspondientes, están disponibles en coefs y SE, respectivamente.

.ul[Instrucciones]: 

- Calcule el estadístico t para cada coeficiente utilizando los objetos predefinidos coefs y SEs. Asígnelos a tstats.

- Calcule los valores-p para cada coeficiente y asígnelos a pval.

- Compruebe con la ayuda de operadores lógicos si las hipótesis se rechazan al 1% de significancia.

---
# 3. Test de hipótesis 

.hi-pink[Sugerencias]  

- El estadístico t para cada coeficiente se define como $t=\frac{\widehat{\beta}_{j}-\beta_{j, 0}}{S E\left(\hat{\beta}_{j}\right)}$

- El valor-p para un test bilateral se computa como $2 \cdot \Phi\left(-\left|t^{a c t}\right|\right)$ donde $t^{a c t}$ denota el estadístico t computado. 

```{r}
coefs <- mod$coefficients
SEs <- coef(summary(mod))[, "Std. Error"] 

# compute el estadístico t para cada coeficiente, asígnelos a `tstat`
tstats <- coefs/SEs
  
# compute los valores-p para todos los test de significancia, asígnelos a `pval`
pvals <- 2*(pnorm(-abs(tstats)))
  
# comprobar si las hipótesis se rechazan al 1% de nivel de significancia
pvals < 0.01
```

---
# 4. Intervalos de confianza

Reconsidere el modelo estimado en el ejercicio anterior 

$$\widehat{m e d v}_{i}=32.828-0.994 \times l s t a t_{i}-0.083 \times c r i m_{i}+0.038 \times a g e_{i}$$

con $ee\left(\widehat{\beta}_{0}\right) = 0.75$, $ee\left(\widehat{\beta}_{1}\right) = 0.05$, $ee\left(\widehat{\beta}_{3}\right) = 0.04$ y $ee\left(\widehat{\beta}_{4}\right) = 0.01$  

que está disponible en el ambiente como mod. 

.ul[Instrucciones]: 

Construya intervalos de confianza al 99% para todos los coeficientes del modelo. Use los intervalos para decidir si las hipótyesis nulas ${H}_{0}: \beta_{j}=0, j=0, 1, 2, 3, 4$ se rechazan al nivel de 1%.

.hi-pink[Sugerencia:] Use la función confint(), vea ?confint. El argumento level establece el nivel de confianza que se utilizará.

```{r}
confint(mod, level = 0.99)
```

---
# 5. Hipótesis conjuntas

A veces nos interesa probar hipótesis conjuntas que imponen restricciones sobre coeficientes de las regresiones múltiples. Por ejemplo, en el modelo

$$\operatorname{med} v_{i}=\beta_{0}+\beta_{1} \times \text {lstat}_{i}+\beta_{2} \times \operatorname{crim}_{i}+\beta_{3} \times a g e_{i}+u_{i}$$
podemos testear $H_{0}: \beta_{2}=\beta_{3}$ versus la alternativa $H_{1}: \beta_{2} \neq \beta_{3}$ (que es una hipótesis conjunta ya que imponemos una restricción a dos coeficientes de regresión).


La idea básica detrás de probar tal hipótesis es realizar dos regresiones y comparar los resultados: para una de las regresiones, imponemos las restricciones de formalizado por la nula (llamamos a este modelo de regresión restringido), mientras que para la otra regresión la restricción queda fuera (a esto lo llamamos el modelo sin restricciones). A partir de este punto de partida construimos un estadístico de prueba que, bajo la nula, sigue una distribución bien conocida, una distribución F.

Sin embargo, en este ejercicio comenzamos con los cálculos iniciales necesarios para construir la prueba estadística.

.ul[Instrucciones]: 

- Estimar el modelo restringido, es decir, el modelo donde la restricción formalizada por $H_{0}: \beta_{2}=\beta_{3}$ se asume que es cierto. Guarde el modelo en model_res.

---
# 5. Hipótesis conjuntas

.ul[Instrucciones]: 

- Compute el SR del modelo restringido y asígnelo a RSSR.

- Estime el modelo sin restringir es decir, el modelo donde se asume que la restricción es falsa. Guárdelo en model_unres.

- Compute el SR del modelo sin restringir y asígnelo a USSR.

.hi-pink[Sugerencias]

- El modelo restringido puede estar escrito como 

$$\operatorname{medv}_{i}=\beta_{0}+\beta_{1} \times \text { lstat }_{i}+\beta_{2} \times \operatorname{crim}_{i}+\beta_{2} \times a g e_{i}+u_{i}$$

que, después de reorganizar, se puede expresar como

$$\operatorname{medv}_{i}=\beta_{0}+\beta_{1} \times \text { lstat}_i+\beta_{2} \times\left(\operatorname{crim}_{i}+a g e_{i}\right)+u_{i}$$

- Tenga en cuenta que los residuos de un modelo de regresión están disponibles como residuos en el objeto lm correspondiente. Entonces puede acceder a ellos como de costumbre a través del operador $.

---
# 5. Hipótesis conjuntas

```{r}
# estime el modelo restringido y guárdelo como `model_res`
model_res <- lm(medv ~ lstat + I(crim + age), data = Boston)
  
# compute el SR del modelo restringido y asígnelo a RSSR
RSSR <- sum(model_res$residuals^2)
  
# estime el modelo irrestricto y guárdelo como `model_unres`
model_unres <- lm(medv ~ lstat + crim + age, data = Boston)
  
# compute el SR del modelo irrestricto y asígnelo a `USSR`
USSR <- sum(model_unres$residuals^2)
```
---
# 5. Hipótesis conjuntas

Después de estimar los modelos y calcular los SSR, ahora tiene que calcular el estadística de prueba y realizar la prueba F. Como se mencionó en el último ejercicio, el estadístico de prueba sigue una distribución F. Más precisamente, nos ocupamos de una distribución $F_{q, n-k-1}$ donde $q$ denota el número de restricciones bajo hipótesis nula y $k$ es número de regresores en el modelo sin restricciones, excluyendo el intercepto.

.ul[Instrucciones]:

- Compute el estadístico F y asígnelo como Fstat.

- Compute el valor-p y asígnelo como apval.

- Chequee si la hipotesis nula si rechaza a un nivel de 1% usando operadores lógicos.

- Verifique sus resultados usando linearHypothesis() e imprimiendo los resultados.


---
# 5. Hipótesis conjuntas

```{r}
# compute el estadístico y asígnelo a `Fstat`
Fstat <- ((RSSR-USSR)/1)/(USSR/(nrow(Boston)-3-1))
  
# compute el valor-p y asígnelo a `pval`
pval <- 1 - pf(Fstat, df1 = 1, df2 = nrow(Boston)-3-1)
  
# chequee si la hipotesis nula si rechaza a un nivel de 1% usando operadores lógicos.
pval < 0.01
  
# verifique ese resultado con `linearHypothesis()`
linearHypothesis(model_unres, "age = crim")
```

